# ğŸš€ Credit Card Fraud Detection Pipeline

A robust end-to-end MLOps project to detect credit card fraud using Apache Airflow for orchestration, Prometheus + Grafana for monitoring, and FastAPI for real-time predictions. This project is containerized using Docker and uses AWS S3 for model artifact storage, DVC for data versioning, and Git for experiment tracking.

---

## ğŸ› ï¸ Tech Stack

- **MLOps Orchestration**: Apache Airflow  
- **Model Serving**: FastAPI  
- **Monitoring**: Prometheus, Grafana  
- **Data Versioning**: DVC  
- **Cloud Storage**: AWS S3  
- **Modeling**: Scikit-learn  
- **Infrastructure**: Docker, Docker Compose  
- **Git Integration**: Git + GitHub

---

## ğŸ“ˆ Project Overview

The pipeline is structured into **two main DAGs**:

### 1ï¸âƒ£ ETL DAG (`ETL.py`)
- **Extract**: Load raw fraud transaction data.
- **Track with DVC**: Push extracted raw data to AWS S3 using DVC.
- **Transform**: Feature engineering (e.g., extract age/date-based features).
- **Load**: Save and version preprocessed data and the fitted preprocessor object.

### 2ï¸âƒ£ Training DAG (`TRAIN.py`)
- **Drift Detection**: Compares incoming data with reference to detect feature drift.
- **Conditional Training**:
  - If **drift is detected**: âŒ Training is **not** triggered.
  - If **no drift detected**: âœ… Model training proceeds.
- **Model Training**: Train fraud detection model.
- **Evaluation & Push**: Evaluate model and push artifacts (model + preprocessor) to S3.

---

## ğŸ“Š Monitoring

This project integrates **Prometheus and Grafana**:

- Prometheus scrapes metrics from FastAPI via `/metrics` exposed using `prometheus_fastapi_instrumentator`.
- Grafana displays metrics dashboards via:
  - `datasources.yml` â€“ Prometheus config
  - `dashboards.json` â€“ Predefined dashboard panel for request stats, latency, etc.

---

## ğŸŒ Application Behavior

### `app.py` (FastAPI Server)
- On startup:
  - Downloads model and preprocessor from S3 (if not already present).
- On POST request from web UI:
  - Preprocesses user input using the pipeline.
  - Makes predictions using the trained model.
  - Renders prediction result in a form using `Jinja2Templates`.

---

## ğŸ—‚ï¸ Project Structure

``` text
.
â”œâ”€â”€ .dvc
â”œâ”€â”€ airflow
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ airflow.cfg
â”‚   â”œâ”€â”€ config
â”‚   â”œâ”€â”€ dags
â”‚   â”‚   â”œâ”€â”€ bash
â”‚   â”‚   â”‚   â”œâ”€â”€ dvc_load_task.sh
â”‚   â”‚   â”‚   â””â”€â”€ dvc_track_raw_data.sh
â”‚   â”‚   â”œâ”€â”€ ETL.py
â”‚   â”‚   â””â”€â”€ TRAIN.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ entry.sh
â”‚   â”œâ”€â”€ plugins
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ scripts
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_extract.py
â”‚       â”œâ”€â”€ data_transform.py
â”‚       â”œâ”€â”€ drift_detect.py
â”‚       â”œâ”€â”€ model_evalpush.py
â”‚       â””â”€â”€ model_trainer.py
â”œâ”€â”€ app.py
â”œâ”€â”€ artifacts
â”‚   â”œâ”€â”€ data_ingestion
â”‚   â”‚   â”œâ”€â”€ fraud_data.csv
â”‚   â”‚   â”œâ”€â”€ fraud_data.csv.dvc
â”‚   â”‚   â””â”€â”€ fraud_data.zip
â”‚   â”œâ”€â”€ data_transformation
â”‚   â”‚   â”œâ”€â”€ preprocessing_object
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessor.jbl
â”‚   â”‚   â”‚   â””â”€â”€ preprocessor.jbl.dvc
â”‚   â”‚   â””â”€â”€ transformed
â”‚   â”‚       â”œâ”€â”€ transformed_data.csv
â”‚   â”‚       â””â”€â”€ transformed_data.csv.dvc
â”‚   â”œâ”€â”€ drift_report
â”‚   â”‚   â””â”€â”€ report.yml
â”‚   â””â”€â”€ model_training
â”‚       â”œâ”€â”€ model.jbl
â”‚       â””â”€â”€ model.jbl.dvc
â”œâ”€â”€ config
â”‚   â”œâ”€â”€ config.yml
â”‚   â”œâ”€â”€ dashboards.yml
â”‚   â”œâ”€â”€ datasources.yml
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ dashboards
â”‚   â””â”€â”€ grafana_dash.json
â”œâ”€â”€ deploy
â”‚   â”œâ”€â”€ model.jbl
â”‚   â””â”€â”€ preprocessor.jbl
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ example.env
â”œâ”€â”€ notebooks
â”‚   â””â”€â”€ credit_card_fraud_ML_project
â”‚       â”œâ”€â”€ data
â”‚       â”‚   â”œâ”€â”€ fraud_data.csv
â”‚       â”‚   â””â”€â”€ fraud_data.csv.zip
â”‚       â””â”€â”€ notebook
â”‚           â”œâ”€â”€ explore.ipynb
â”‚           â””â”€â”€ file.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cloud_storage
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ s3_storage.py
â”‚   â”œâ”€â”€ configuration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config_manager.py
â”‚   â”œâ”€â”€ constants
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ entity
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ artifact_entity.py
â”‚   â”‚   â”œâ”€â”€ config_entity.py
â”‚   â”‚   â””â”€â”€ prediction_input.py
â”‚   â”œâ”€â”€ feature_transform
â”‚   â”‚   â””â”€â”€ date_age.py
â”‚   â”œâ”€â”€ logger
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ artifact_serializer.py
â”‚       â””â”€â”€ common.py
â”œâ”€â”€ template
â”‚   â””â”€â”€ form.html
â”œâ”€â”€ testing.py
â””â”€â”€ uv.lock

```
---

## âš™ï¸ How to Run Locally

```bash
# Clone the repo
git clone https://github.com/your-username/credit-card-fraud-mlops.git
cd credit-card-fraud-mlops

# set env.example variables
# Spin up everything
docker compose up --build -d

# Access Airflow: http://localhost:8080
# Access FastAPI: http://localhost:8000
# Access Grafana: http://localhost:3000
```# ETE_MLOps_Credit_Card_Fraud_Prediction
